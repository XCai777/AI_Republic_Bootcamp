{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "86otUaliRqcT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "402f7efb-5f3b-4c6d-db7d-98d59fcd56ee"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/openai/swarm.git\n",
            "  Cloning https://github.com/openai/swarm.git to /tmp/pip-req-build-56uiyx12\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/openai/swarm.git /tmp/pip-req-build-56uiyx12\n",
            "  Resolved https://github.com/openai/swarm.git to commit 9db581cecaacea0d46a933d6453c312b034dbf47\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from swarm==0.1.0) (1.26.4)\n",
            "Requirement already satisfied: openai>=1.33.0 in /usr/local/lib/python3.10/dist-packages (from swarm==0.1.0) (1.54.4)\n",
            "Requirement already satisfied: pytest in /usr/local/lib/python3.10/dist-packages (from swarm==0.1.0) (8.3.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from swarm==0.1.0) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from swarm==0.1.0) (4.66.6)\n",
            "Collecting pre-commit (from swarm==0.1.0)\n",
            "  Downloading pre_commit-4.0.1-py2.py3-none-any.whl.metadata (1.3 kB)\n",
            "Collecting instructor (from swarm==0.1.0)\n",
            "  Downloading instructor-1.7.0-py3-none-any.whl.metadata (17 kB)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai>=1.33.0->swarm==0.1.0) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from openai>=1.33.0->swarm==0.1.0) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from openai>=1.33.0->swarm==0.1.0) (0.27.2)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from openai>=1.33.0->swarm==0.1.0) (0.7.1)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai>=1.33.0->swarm==0.1.0) (2.9.2)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai>=1.33.0->swarm==0.1.0) (1.3.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.10/dist-packages (from openai>=1.33.0->swarm==0.1.0) (4.12.2)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.9.1 in /usr/local/lib/python3.10/dist-packages (from instructor->swarm==0.1.0) (3.11.2)\n",
            "Requirement already satisfied: docstring-parser<0.17,>=0.16 in /usr/local/lib/python3.10/dist-packages (from instructor->swarm==0.1.0) (0.16)\n",
            "Requirement already satisfied: jinja2<4.0.0,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from instructor->swarm==0.1.0) (3.1.4)\n",
            "Collecting jiter<1,>=0.4.0 (from openai>=1.33.0->swarm==0.1.0)\n",
            "  Downloading jiter-0.6.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.2 kB)\n",
            "Requirement already satisfied: pydantic-core<3.0.0,>=2.18.0 in /usr/local/lib/python3.10/dist-packages (from instructor->swarm==0.1.0) (2.23.4)\n",
            "Requirement already satisfied: rich<14.0.0,>=13.7.0 in /usr/local/lib/python3.10/dist-packages (from instructor->swarm==0.1.0) (13.9.4)\n",
            "Requirement already satisfied: tenacity<10.0.0,>=9.0.0 in /usr/local/lib/python3.10/dist-packages (from instructor->swarm==0.1.0) (9.0.0)\n",
            "Requirement already satisfied: typer<1.0.0,>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from instructor->swarm==0.1.0) (0.13.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->swarm==0.1.0) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->swarm==0.1.0) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->swarm==0.1.0) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->swarm==0.1.0) (2024.8.30)\n",
            "Collecting cfgv>=2.0.0 (from pre-commit->swarm==0.1.0)\n",
            "  Downloading cfgv-3.4.0-py2.py3-none-any.whl.metadata (8.5 kB)\n",
            "Collecting identify>=1.0.0 (from pre-commit->swarm==0.1.0)\n",
            "  Downloading identify-2.6.3-py2.py3-none-any.whl.metadata (4.4 kB)\n",
            "Collecting nodeenv>=0.11.1 (from pre-commit->swarm==0.1.0)\n",
            "  Downloading nodeenv-1.9.1-py2.py3-none-any.whl.metadata (21 kB)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from pre-commit->swarm==0.1.0) (6.0.2)\n",
            "Collecting virtualenv>=20.10.0 (from pre-commit->swarm==0.1.0)\n",
            "  Downloading virtualenv-20.28.0-py3-none-any.whl.metadata (4.4 kB)\n",
            "Requirement already satisfied: iniconfig in /usr/local/lib/python3.10/dist-packages (from pytest->swarm==0.1.0) (2.0.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from pytest->swarm==0.1.0) (24.2)\n",
            "Requirement already satisfied: pluggy<2,>=1.5 in /usr/local/lib/python3.10/dist-packages (from pytest->swarm==0.1.0) (1.5.0)\n",
            "Requirement already satisfied: exceptiongroup>=1.0.0rc8 in /usr/local/lib/python3.10/dist-packages (from pytest->swarm==0.1.0) (1.2.2)\n",
            "Requirement already satisfied: tomli>=1 in /usr/local/lib/python3.10/dist-packages (from pytest->swarm==0.1.0) (2.1.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.9.1->instructor->swarm==0.1.0) (2.4.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.9.1->instructor->swarm==0.1.0) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.9.1->instructor->swarm==0.1.0) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.9.1->instructor->swarm==0.1.0) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.9.1->instructor->swarm==0.1.0) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.9.1->instructor->swarm==0.1.0) (0.2.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.9.1->instructor->swarm==0.1.0) (1.17.2)\n",
            "Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.9.1->instructor->swarm==0.1.0) (4.0.3)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai>=1.33.0->swarm==0.1.0) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai>=1.33.0->swarm==0.1.0) (0.14.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2<4.0.0,>=3.1.4->instructor->swarm==0.1.0) (3.0.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai>=1.33.0->swarm==0.1.0) (0.7.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich<14.0.0,>=13.7.0->instructor->swarm==0.1.0) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich<14.0.0,>=13.7.0->instructor->swarm==0.1.0) (2.18.0)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.9.0->instructor->swarm==0.1.0) (8.1.7)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.9.0->instructor->swarm==0.1.0) (1.5.4)\n",
            "Collecting distlib<1,>=0.3.7 (from virtualenv>=20.10.0->pre-commit->swarm==0.1.0)\n",
            "  Downloading distlib-0.3.9-py2.py3-none-any.whl.metadata (5.2 kB)\n",
            "Requirement already satisfied: filelock<4,>=3.12.2 in /usr/local/lib/python3.10/dist-packages (from virtualenv>=20.10.0->pre-commit->swarm==0.1.0) (3.16.1)\n",
            "Requirement already satisfied: platformdirs<5,>=3.9.1 in /usr/local/lib/python3.10/dist-packages (from virtualenv>=20.10.0->pre-commit->swarm==0.1.0) (4.3.6)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich<14.0.0,>=13.7.0->instructor->swarm==0.1.0) (0.1.2)\n",
            "Downloading instructor-1.7.0-py3-none-any.whl (70 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m70.1/70.1 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pre_commit-4.0.1-py2.py3-none-any.whl (218 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m218.7/218.7 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading cfgv-3.4.0-py2.py3-none-any.whl (7.2 kB)\n",
            "Downloading identify-2.6.3-py2.py3-none-any.whl (99 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.0/99.0 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jiter-0.6.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (325 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m325.2/325.2 kB\u001b[0m \u001b[31m16.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nodeenv-1.9.1-py2.py3-none-any.whl (22 kB)\n",
            "Downloading virtualenv-20.28.0-py3-none-any.whl (4.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.3/4.3 MB\u001b[0m \u001b[31m42.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading distlib-0.3.9-py2.py3-none-any.whl (468 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m469.0/469.0 kB\u001b[0m \u001b[31m20.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: swarm\n",
            "  Building wheel for swarm (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for swarm: filename=swarm-0.1.0-py3-none-any.whl size=25999 sha256=b6a62ca9d1573bcc85295fd8ec56c9004b733991a21ac9aa0e3bfd5cdc4793d2\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-d9o4ngz8/wheels/46/9a/f7/7b8bbb674ae80ef0f62a632706c2c4cdfcf708e4da32e4e256\n",
            "Successfully built swarm\n",
            "Installing collected packages: distlib, virtualenv, nodeenv, jiter, identify, cfgv, pre-commit, instructor, swarm\n",
            "  Attempting uninstall: jiter\n",
            "    Found existing installation: jiter 0.7.1\n",
            "    Uninstalling jiter-0.7.1:\n",
            "      Successfully uninstalled jiter-0.7.1\n",
            "Successfully installed cfgv-3.4.0 distlib-0.3.9 identify-2.6.3 instructor-1.7.0 jiter-0.6.1 nodeenv-1.9.1 pre-commit-4.0.1 swarm-0.1.0 virtualenv-20.28.0\n",
            "Requirement already satisfied: openai in /usr/local/lib/python3.10/dist-packages (1.54.4)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from openai) (0.27.2)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from openai) (0.6.1)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.9.2)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.6)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.10/dist-packages (from openai) (4.12.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2024.8.30)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.23.4)\n",
            "Collecting firecrawl-py\n",
            "  Downloading firecrawl_py-1.6.1-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from firecrawl-py) (2.32.3)\n",
            "Collecting python-dotenv (from firecrawl-py)\n",
            "  Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
            "Collecting websockets (from firecrawl-py)\n",
            "  Downloading websockets-14.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
            "Requirement already satisfied: nest-asyncio in /usr/local/lib/python3.10/dist-packages (from firecrawl-py) (1.6.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->firecrawl-py) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->firecrawl-py) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->firecrawl-py) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->firecrawl-py) (2024.8.30)\n",
            "Downloading firecrawl_py-1.6.1-py3-none-any.whl (16 kB)\n",
            "Downloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
            "Downloading websockets-14.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (168 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m168.2/168.2 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: websockets, python-dotenv, firecrawl-py\n",
            "Successfully installed firecrawl-py-1.6.1 python-dotenv-1.0.1 websockets-14.1\n"
          ]
        }
      ],
      "source": [
        "!pip install git+https://github.com/openai/swarm.git\n",
        "!pip install openai\n",
        "!pip install firecrawl-py"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from firecrawl import FirecrawlApp\n",
        "from swarm import Agent, Swarm\n",
        "from openai import OpenAI\n",
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "FB6Z6PNuR3Zw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "afda5c3e-a8c8-48d5-a263-a595abe050fd"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pydantic/_internal/_fields.py:172: UserWarning: Field name \"schema\" in \"FirecrawlApp.ExtractParams\" shadows an attribute in parent \"BaseModel\"\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "api = OpenAI(api_key=\"\") #OpenAI Token Here"
      ],
      "metadata": {
        "id": "4nRVD-44R4-l"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "client = Swarm(api)"
      ],
      "metadata": {
        "id": "qEcrPN8BR6yE"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv('https://raw.githubusercontent.com/XCai777/AI_Republic_Bootcamp/refs/heads/main/AI_First_Day_6/ai_first_sales_data_sales.csv')"
      ],
      "metadata": {
        "id": "n4N3Y0YFR8Dj"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data['date'] = pd.to_datetime(data['date'])\n",
        "data['month'] = data['date'].dt.month\n",
        "data['day'] = data['date'].dt.day\n",
        "data['weekday'] = data['date'].dt.weekday\n",
        "\n",
        "def clean_currency(value):\n",
        "    \"\"\"\n",
        "    Removes non-numeric characters and converts to integer.\n",
        "    \"\"\"\n",
        "    if isinstance(value, str):  # Ensure it's a string\n",
        "        # Remove currency symbols and commas\n",
        "        cleaned_value = value.replace('₱', '').replace(',', '')\n",
        "        # Convert to integer\n",
        "        return int(float(cleaned_value))  # Handles decimals\n",
        "    return value  # Return value if it's already numeric\n",
        "\n",
        "# Apply the function to the 'revenue' column\n",
        "data['ad spend'] = data['ad spend'].apply(clean_currency)\n",
        "data['revenue'] = data['revenue'].apply(clean_currency)"
      ],
      "metadata": {
        "id": "vTxFanV9Xo0U"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **HAND OFF**\n"
      ],
      "metadata": {
        "id": "cuh3Ov3CWPlK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def analyze_cost_effectiveness():\n",
        "      # Calculate cost per transaction and revenue per spend\n",
        "      data['cost_per_transaction'] = data['ad spend'] / (data['transactions'] + 1)\n",
        "      data['revenue_per_spend'] = data['revenue'] / (data['ad spend'] + 1)\n",
        "\n",
        "      # Identify the top-performing traffic sources\n",
        "      grouped = data.groupby('source').agg({\n",
        "            'ad spend': 'sum',\n",
        "            'transactions': 'sum',\n",
        "            'revenue': 'sum'\n",
        "      })\n",
        "      grouped['revenue_per_spend'] = grouped['revenue'] / (grouped['ad spend'] + 1)\n",
        "      return grouped.sort_values('revenue_per_spend', ascending=False)\n",
        "\n",
        "def optimize_roi():\n",
        "      # Identify campaigns with low ROI\n",
        "      data['roi'] = data['revenue'] / (data['ad spend'] + 1)\n",
        "      low_roi = data[data['roi'] < 1]\n",
        "      return low_roi[['source', 'medium', 'ad spend', 'revenue', 'roi']]\n",
        "\n",
        "def flag_wastage():\n",
        "      # Highlight campaigns with high spend but low conversions\n",
        "      wastage = data[(data['ad spend'] > 1000) & (data['transactions'] < 10)]\n",
        "      return wastage[['source', 'medium', 'ad spend', 'transactions']]\n",
        "\n",
        "def suggest_scaling():\n",
        "      # Recommend scaling for campaigns with high ROI\n",
        "      high_roi = data[data['roi'] > 3]\n",
        "      return high_roi[['source', 'medium', 'ad spend', 'revenue', 'roi']]"
      ],
      "metadata": {
        "id": "GyRtjYs1WLm1"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **AGENTS**"
      ],
      "metadata": {
        "id": "-9z8suSDptCw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cost_analyst_agent = Agent(\n",
        "    name=\"User Interface Agent\",\n",
        "    model=\"gpt-4o-mini\",\n",
        "    instructions=\"You are a cost analyst agent speciliazed in analyzing cost-effectiveness of different traffic sources and marketing campaigns.\",\n",
        "    functions=[analyze_cost_effectiveness],\n",
        ")\n",
        "\n",
        "roi_optimizer_agent = Agent(\n",
        "    name=\"ROI Optimizer Agent\",\n",
        "    model=\"gpt-4o-mini\",\n",
        "    instructions=\"You are an ROI Optimizer Agent that calculates ROI per source/medium and identify underperforming campaigns.\",\n",
        "    functions=[optimize_roi],\n",
        ")\n",
        "\n",
        "wastage_agent = Agent(\n",
        "    name=\"Wastage Analyst Agent\",\n",
        "    model=\"gpt-4o-mini\",\n",
        "    instructions=\"You are a wastage analyst agent that identifies campaigns with high spend but low conversion\",\n",
        "    functions=[flag_wastage],\n",
        ")\n",
        "\n",
        "scaling_strategist_agent = Agent(\n",
        "    name=\"Scaling Strategist Agent\",\n",
        "    model=\"gpt-4o-mini\",\n",
        "    instructions=\"You are a scaling strategist agent that determines high-performing sources, devices, or campaigns that can be scaled up profitably.\",\n",
        "    functions=[suggest_scaling],\n",
        "    )"
      ],
      "metadata": {
        "id": "j99_nblYpsL2"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Output**"
      ],
      "metadata": {
        "id": "islIcBvt24w4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Run the Cost Analyst Agent\n",
        "cost_analyst_response = client.run(\n",
        "      agent=cost_analyst_agent,\n",
        "      messages=[{\"role\": \"user\", \"content\": \"Based on the data, I want to know the cost-effectiveness.\"}]\n",
        "  )\n",
        "\n",
        "print(\"\\nCost Analysis Results:\")\n",
        "print(cost_analyst_response.messages[-1][\"content\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6svGnQcixDO0",
        "outputId": "a22ef501-59c5-4a8f-a9d9-2a62c0b215c2"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Cost Analysis Results:\n",
            "Here is the cost-effectiveness analysis of various traffic sources based on ad spend, transactions, revenue, and revenue per spend:\n",
            "\n",
            "| Source             | Ad Spend     | Transactions | Revenue       | Revenue per Spend |\n",
            "|--------------------|--------------|--------------|---------------|--------------------|\n",
            "| (direct)           | 2,758,336,907| 197,467      | 1,256,781,676 | 0.455630           |\n",
            "| google             | 6,490,566,537| 388,169      | 2,406,178,484 | 0.370719           |\n",
            "| facebook           | 7,141,533,169| 377,909      | 2,465,492,458 | 0.345233           |\n",
            "| tiktok             | 2,308,870,038| 55,397       | 346,623,075   | 0.150127           |\n",
            "| cityads            | 1,616,344,923| 11,904       | 75,351,293    | 0.046618           |\n",
            "| instagram          | 2,004,995,201| 14,501       | 86,724,053    | 0.043254           |\n",
            "| promo              | 657,223,313  | 4,395        | 28,281,240    | 0.043031           |\n",
            "| co-promo           | 510,268,396  | 2,544        | 17,652,162    | 0.034594           |\n",
            "| newsletter         | 936,253,379  | 1,955        | 11,733,349    | 0.012532           |\n",
            "| advertise          | 187,301,342  | 372          | 2,322,300     | 0.012399           |\n",
            "| DuckDuckGo        | 617,281,511   | 693          | 4,858,295     | 0.007870           |\n",
            "| mytarget           | 292,067,191  | 318          | 2,181,073     | 0.007468           |\n",
            "| other              | 1,339,509,305| 1,537        | 9,699,979     | 0.007241           |\n",
            "| actionpay          | 424,164,578  | 470          | 2,930,145     | 0.006908           |\n",
            "| opmcpa             | 304,170,255  | 350          | 2,076,529     | 0.006827           |\n",
            "| bing               | 454,110,873  | 373          | 2,492,546     | 0.005489           |\n",
            "| vk                 | 773,382,832  | 598          | 3,256,876     | 0.004211           |\n",
            "| exponea            | 11,444,746   | 5            | 46,420        | 0.004056           |\n",
            "| sailplay           | 27,732,290    | 10           | 68,235        | 0.002460           |\n",
            "| facebook_direct    | 58,927,539    | 10           | 68,334        | 0.001160           |\n",
            "| baidu              | 11,410,882    | 0            | 0             | 0.000000           |\n",
            "| youtube            | 46,165,502    | 0            | 0             | 0.000000           |\n",
            "\n",
            "### Summary Insights:\n",
            "- The **most cost-effective source** is **(direct)** with a revenue per spend of **0.455630**.\n",
            "- **Google** and **Facebook** also show good performance with revenue per spend ratios of **0.370719** and **0.345233** respectively.\n",
            "- The least effective sources include **sailplay**, **facebook_direct**, **baidu**, and **youtube**, which have very low or zero revenue generated relative to their ad spend.\n",
            "\n",
            "This breakdown can help focus marketing efforts on the most effective channels.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Run the ROI Optimizer Agent\n",
        "roi_optimizer_response = client.run(\n",
        "      agent=roi_optimizer_agent,\n",
        "      messages=[{\"role\": \"user\", \"content\": \"Based on the data, I want to know how may ROI can be optimized.\"}]\n",
        "  )\n",
        "\n",
        "print(\"\\nROI Optimizer Results:\")\n",
        "print(roi_optimizer_response.messages[-1][\"content\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MUpa5kBayXgZ",
        "outputId": "6f25abd8-6696-4a93-96e8-b1c2581c626c"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ROI Optimizer Results:\n",
            "The ROI data reveals several sources and mediums with varying levels of performance. Here are some insights based on the provided information:\n",
            "\n",
            "1. **Underperforming Campaigns**:\n",
            "   - Many campaigns have a low ROI, indicating that the revenue generated is significantly lower than the ad spend.\n",
            "   - Examples of underperforming sources include:\n",
            "     - TikTok (cpa) with an ROI of 0.106786.\n",
            "     - Direct traffic campaigns with ROIs as low as 0.006380.\n",
            "     - Co-promotion via email yielding an ROI of 0.089354.\n",
            "\n",
            "2. **Better Performing Campaigns**:\n",
            "   - The \"facebook organic\" channel has a relatively higher ROI of 0.760383.\n",
            "   - Other channels like \"google cpc\" have a moderate ROI of 0.655382, indicating potential for optimization without significant changes.\n",
            "\n",
            "3. **Potential Areas for Optimization**:\n",
            "   - Focus on campaigns with a ROI below 0.2 to analyze why they are underperforming and identify improvements.\n",
            "   - Assess the performance of channels that are underperforming despite high ad spend.\n",
            "\n",
            "This analysis highlights specific areas where ROI can be optimized, particularly by addressing campaigns with low returns on ad spend.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Run the Wastage Analyst Agent\n",
        "wastage_response = client.run(\n",
        "      agent=wastage_agent,\n",
        "      messages=[{\"role\": \"user\", \"content\": \"Based on the data, I want to know the wastage of each campaigns.\"}]\n",
        "  )\n",
        "\n",
        "print(\"\\nWastage Results:\")\n",
        "print(wastage_response.messages[-1][\"content\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YKYZRBtAyX8M",
        "outputId": "b31eeb04-34bf-4783-ecbc-77f97cc30c75"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Wastage Results:\n",
            "Here is a summary of the campaigns with their corresponding ad spend and transactions:\n",
            "\n",
            "| Source      | Medium | Ad Spend | Transactions |\n",
            "|-------------|--------|----------|--------------|\n",
            "| tiktok      | cpa    | 369185   | 6            |\n",
            "| instagram   | cpc    | 372718   | 6            |\n",
            "| instagram   | cpc    | 833607   | 4            |\n",
            "| (direct)    | (none) | 470848   | 4            |\n",
            "| tiktok      | cpa    | 526308   | 9            |\n",
            "| (direct)    | (none) | 491731   | 4            |\n",
            "| co-promo    | email  | 433598   | 1            |\n",
            "| google      | cpc    | 198570   | 1            |\n",
            "| (direct)    | (none) | 684341   | 1            |\n",
            "| tiktok      | cpa    | 523643   | 4            |\n",
            "\n",
            "This data provides insight into campaign performance, with ad spends that appear high but yield low conversions in some cases, such as those with only 1 or 4 transactions. Would you like a more detailed analysis or a specific focus on campaigns that have the highest spend with the least conversions?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Run the Scaling Strategist Agent\n",
        "scaling_strategist_response = client.run(\n",
        "      agent=scaling_strategist_agent,\n",
        "      messages=[{\"role\": \"user\", \"content\": \"Based on the data, I want to know how I can scale my business.\"}]\n",
        "  )\n",
        "\n",
        "print(\"\\nScaling Strategist Results:\")\n",
        "print(scaling_strategist_response.messages[-1][\"content\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bq1hScYqyYLf",
        "outputId": "f1315cc6-7ec5-401b-a8a4-737601c6291b"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Scaling Strategist Results:\n",
            "To determine how to scale your business effectively, I analyzed the data based on sources, mediums, ad spend, revenue, and return on investment (ROI). Here are some highlighted insights based on high ROI and revenue potential:\n",
            "\n",
            "1. **High-Performing Ad Spend**:\n",
            "   - **Facebook CPC**: The campaigns with CPC (Cost Per Click) on Facebook performed particularly well, such as one with an ad spend of $162,954 generating $988,383 in revenue (ROI of 6.07). This indicates significant potential for scaling in this area.\n",
            "   - **Direct Source**: Several direct campaigns have shown exceptionally high ROI with one instance reaching a 12.53 ROI on an ad spend of $330,944 generating over $4.1 million in revenue.\n",
            "\n",
            "2. **Organic Efforts**:\n",
            "   - **Google Organic**: With a notable ROI of 3.93 at an ad spend of $357,920 generating $1,406,743, focusing on organic search efforts may bring scalable growth without direct ad costs.\n",
            "   - **Facebook Organic**: The organic source on Facebook also has a respectable ROI of 3.61, which suggests there might be additional growth opportunities by enhancing content engagement and reach.\n",
            "\n",
            "3. **Scaling Recommendations**:\n",
            "   - **Increase Facebook CPC Budget**: Given the success and high ROI from Facebook CPC campaigns, consider increasing the budget in this area to capitalize on its profitability.\n",
            "   - **Enhance Direct Marketing Efforts**: As certain direct campaigns have shown strong returns, investigate further into this channel to understand what drives conversions, perhaps enhancing sales funnels or refining customer outreach.\n",
            "   - **Optimize for Organic Growth**: Strengthening organic traffic (especially on Google) through SEO and content creation could lead to sustainable growth without the cost pressure of paid campaigns.\n",
            "\n",
            "In conclusion, focusing on efficient and high-performing ad sources such as Facebook CPC, enhancing direct engagement, and optimizing organic visibility can help scale your business profitably.\n"
          ]
        }
      ]
    }
  ]
}
